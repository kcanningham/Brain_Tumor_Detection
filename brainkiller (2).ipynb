{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08057fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac805c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1='https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor'\n",
    "dataset2='https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69936450",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir1='.\\\\brain-tumor' \n",
    "data_dir2='.\\\\brain-mri-images-for-brain-tumor-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "\n",
    "paths=[]\n",
    "\n",
    "for dirname, _, filenames in os.walk('.\\\\brain-mri-images-for-brain-tumor-detection'):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7c73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f623721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "import cv2      #open cv\n",
    "\n",
    "\n",
    "from PIL import Image \n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d4295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour(image , plot = False):\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)                         #grayscaling the images\n",
    "    grayscale = cv2.GaussianBlur(grayscale, (5,5),0)                            #blur the image to bring it under the threshold\n",
    "    threshold_image = cv2.threshold(grayscale, 50, 255, cv2.THRESH_BINARY)[1]   #convert these grayscaled images to binary images\n",
    "    threshold_image = cv2.erode(threshold_image, None, iterations=2)            #to remove the regions of noise\n",
    "    threshold_image = cv2.dilate(threshold_image, None, iterations=2)           #to remove all the noises around the image\n",
    "    \n",
    "    #Now we need to find the contour and clean it to get what is inside the image.\n",
    "    contour = cv2.findContours(threshold_image.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    \n",
    "     #we grab the largest contour using the max.\n",
    "    contour = imutils.grab_contours(contour)\n",
    "    c = max(contour, key=cv2.contourArea)\n",
    "    \n",
    "    #Now we limit the image by finding it's extreme points.\n",
    "    ext_left = tuple(c[c[:,:,0].argmin()][0])\n",
    "    ext_right = tuple(c[c[:,:,0].argmax()][0])\n",
    "    ext_top = tuple(c[c[:,:,1].argmin()][0])\n",
    "    ext_bot = tuple(c[c[:,:,1].argmax()][0])\n",
    "    \n",
    "    processed_image = image[ext_top[1]:ext_bot[1],ext_left[0]:ext_right[0]]\n",
    "        \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                       top= False, bottom= False,left= False,right= False,\n",
    "                        labeltop= False, labelbottom= False,\n",
    "                        labelleft= False,labelright= False)\n",
    "        plt.title(\"ORIGINAL\")\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(processed_image)\n",
    "        \n",
    "        plt.tick_params(axis=\"both\", which=\"both\",\n",
    "                       top= False, bottom= False,left= False,right= False,\n",
    "                        labeltop= False, labelbottom= False,\n",
    "                        labelleft= False,labelright= False)\n",
    "        plt.title(\"PROCESSED\")\n",
    "        plt.show()\n",
    "        \n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b8a620",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpaths\u001b[49m:\n\u001b[0;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(path)\n\u001b[0;32m      3\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    #img.save()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f799427",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    img = cv2.imread(path)\n",
    "    img = contour(img, True)\n",
    "    \"\"\"plt.imsave(img,path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images with tumor\n",
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "for r, d, f in os.walk(r'.\\yes'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facafe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images without tumor\n",
    "\n",
    "paths = []\n",
    "for r, d, f in os.walk(r\".\\no\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53535960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape(139,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d36c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e166031",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def names(cat):\n",
    "    if cat==0:\n",
    "        return 'Tumor detected'\n",
    "    else:\n",
    "        return 'No detected tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c94f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "img = Image.open(r\"./yes/Y69.jpg\")\n",
    "x = np.array(img.resize((128,128)))\n",
    "x = x.reshape(1,128,128,3)\n",
    "res = model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "img = Image.open(r\"./no/N5.jpg\")\n",
    "x = np.array(img.resize((128,128)))\n",
    "x = x.reshape(1,128,128,3)\n",
    "res = model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913e189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
